{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqt_yzRy16Wj"
   },
   "source": [
    "## Task\n",
    "\n",
    "In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vBP3WN2O16Wp"
   },
   "outputs": [],
   "source": [
    "# Load up store_income_data.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Libraries\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n",
    "df = pd.read_csv('store_income_data_task.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItqLwumA16Wr"
   },
   "source": [
    "1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sLkzt4Hr16Wr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 unique countries\n",
      "There are 37 unique countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['united states/', 'britain', 'united states', 'britain/',\n",
       "       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n",
       "       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n",
       "       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n",
       "       'america.', 's.a..', 'united states of america.',\n",
       "       'united states of america/', 'united states.',\n",
       "       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n",
       "       's. africasouth africa/', 'united kingdom/',\n",
       "       's. africasouth africa.', '.'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = df['country'].unique()\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "\n",
    "# convert to lowercase\n",
    "df['country'] = df['country'].str.lower()\n",
    "\n",
    "# Remove trailing white spaces\n",
    "df['country'] = df['country'].str.strip()\n",
    "countries = df['country'].unique()\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6dcDc4P16Ws"
   },
   "source": [
    "2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qeV3CxMR16Ws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 unique countries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Telecom Italia S.P.A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys</td>\n",
       "      <td>$61199426.97</td>\n",
       "      <td>3-12-2010</td>\n",
       "      <td>south africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>zsussans2o@discuz.net</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$78947711.82</td>\n",
       "      <td>7-12-2006</td>\n",
       "      <td>south africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>ON Semiconductor Corporation</td>\n",
       "      <td>dmcaneny2p@friendfeed.com</td>\n",
       "      <td>Outdoors</td>\n",
       "      <td>$856142.71</td>\n",
       "      <td>26-3-1963</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>International Speedway Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$91817502.46</td>\n",
       "      <td>23-10-2001</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Entegra Financial Corp.</td>\n",
       "      <td>gbowling2r@vimeo.com</td>\n",
       "      <td>Toys</td>\n",
       "      <td>$87400217.97</td>\n",
       "      <td>5-3-2002</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                          store_name                store_email  \\\n",
       "0     1          Cullen/Frost Bankers, Inc.                        NaN   \n",
       "1     2                 Nordson Corporation                        NaN   \n",
       "2     3               Stag Industrial, Inc.                        NaN   \n",
       "3     4                 FIRST REPUBLIC BANK         ecanadine3@fc2.com   \n",
       "4     5         Mercantile Bank Corporation                        NaN   \n",
       "..  ...                                 ...                        ...   \n",
       "95   96               Telecom Italia S.P.A.                        NaN   \n",
       "96   97         Bank of America Corporation      zsussans2o@discuz.net   \n",
       "97   98        ON Semiconductor Corporation  dmcaneny2p@friendfeed.com   \n",
       "98   99  International Speedway Corporation                        NaN   \n",
       "99  100             Entegra Financial Corp.       gbowling2r@vimeo.com   \n",
       "\n",
       "    department        income date_measured         country  \n",
       "0     Clothing  $54438554.24      4-2-2006   united states  \n",
       "1        Tools  $41744177.01      4-1-2006  united kingdom  \n",
       "2       Beauty  $36152340.34     12-9-2003   united states  \n",
       "3   Automotive   $8928350.04      8-5-2006  united kingdom  \n",
       "4         Baby  $33552742.32     21-1-1973  united kingdom  \n",
       "..         ...           ...           ...             ...  \n",
       "95        Toys  $61199426.97     3-12-2010    south africa  \n",
       "96  Automotive  $78947711.82     7-12-2006    south africa  \n",
       "97    Outdoors    $856142.71     26-3-1963  united kingdom  \n",
       "98  Automotive  $91817502.46    23-10-2001   united states  \n",
       "99        Toys  $87400217.97      5-3-2002  united kingdom  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 closest matches to \"united kingdom\"\n",
    "matches = fuzzywuzzy.process.extract(\"uk\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# Function to replace rows in the provided column of the provided DataFrame\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 60):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # Get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # Only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # Get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # Replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # Let us know when the function is done\n",
    "    # print(\"All done!\")\n",
    "\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"england\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"britain\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united kingdom\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"america\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states of america\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"south africa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"u.k.\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"uk\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"sa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"s.a.\")\n",
    "#replace_matches_in_column(df=df, column='country', string_to_match=\"/\")\n",
    "\n",
    "# get all the unique values in the 'country' column\n",
    "# countries = df['country'].unique()\n",
    "\n",
    "# print(f\"There are {len(countries)} unique countries\")\n",
    "# countries\n",
    "\n",
    "df.replace('britain', 'united kingdom', inplace=True)\n",
    "df.replace('england', 'united kingdom', inplace=True)\n",
    "df.replace('u.k.', 'united kingdom', inplace=True)\n",
    "df.replace('uk', 'united kingdom', inplace=True)\n",
    "df.replace('united states of america', 'united states', inplace=True)\n",
    "df.replace('america', 'united states', inplace=True)\n",
    "df.replace('sa', 'south africa', inplace=True)\n",
    "df.replace('s.a.', 'south africa', inplace=True)\n",
    "df.replace('', 'NaN', inplace=True)\n",
    "df.replace('/', 'NaN', inplace=True)\n",
    "df.replace('.', 'NaN', inplace=True)\n",
    "\n",
    "df = df.dropna(subset=['country'])\n",
    "\n",
    "# Get all the unique values in the 'country' column\n",
    "countries = df['country'].unique()\n",
    "\n",
    "countries\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJZDMTwP16Ws"
   },
   "source": [
    "3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gMJbN84P16Wt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>2006-02-04</td>\n",
       "      <td>united states</td>\n",
       "      <td>6649 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6680 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>2003-09-12</td>\n",
       "      <td>united states</td>\n",
       "      <td>7525 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>2006-05-08</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>6556 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>1973-01-21</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>18716 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   store_name         store_email  department  \\\n",
       "0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n",
       "1   2          Nordson Corporation                 NaN       Tools   \n",
       "2   3        Stag Industrial, Inc.                 NaN      Beauty   \n",
       "3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n",
       "4   5  Mercantile Bank Corporation                 NaN        Baby   \n",
       "\n",
       "         income date_measured         country   days_ago  \n",
       "0  $54438554.24    2006-02-04   united states  6649 days  \n",
       "1  $41744177.01    2006-01-04  united kingdom  6680 days  \n",
       "2  $36152340.34    2003-09-12   united states  7525 days  \n",
       "3   $8928350.04    2006-05-08  united kingdom  6556 days  \n",
       "4  $33552742.32    1973-01-21  united kingdom 18716 days  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "from datetime import date\n",
    "\n",
    "# Convert 'date_measured' to datetime64\n",
    "df['date_measured'] = pd.to_datetime(df['date_measured'], format='%d-%m-%Y')\n",
    "\n",
    "# Initialise 'days_ago' column with today's date in datetime64 type\n",
    "df['days_ago'] = pd.to_datetime(date.today(), format='%d-%m-%Y')\n",
    "\n",
    "# Subtract the date measured from todays date to get the number of days that have passed\n",
    "df['days_ago'] = df['days_ago'] - df['date_measured']\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
